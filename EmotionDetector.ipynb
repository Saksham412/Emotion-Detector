{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4cc1dc-015c-4de5-bf97-6820f6fece94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (2.16.1)\n",
      "Requirement already satisfied: opencv-python in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (4.10.0.82)\n",
      "Requirement already satisfied: matplotlib in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (3.9.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (4.12.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: rich in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/saksham/anaconda3/envs/emotion/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e81e1df-c29f-455d-91d0-ff56f3abd63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- -----------\n",
      "absl-py                      2.1.0\n",
      "astunparse                   1.6.3\n",
      "certifi                      2024.6.2\n",
      "charset-normalizer           3.3.2\n",
      "contourpy                    1.2.1\n",
      "cycler                       0.12.1\n",
      "flatbuffers                  24.3.25\n",
      "fonttools                    4.53.0\n",
      "gast                         0.5.4\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.64.1\n",
      "h5py                         3.11.0\n",
      "idna                         3.7\n",
      "importlib_metadata           7.1.0\n",
      "importlib_resources          6.4.0\n",
      "keras                        3.3.3\n",
      "kiwisolver                   1.4.5\n",
      "libclang                     18.1.1\n",
      "Markdown                     3.6\n",
      "markdown-it-py               3.0.0\n",
      "MarkupSafe                   2.1.5\n",
      "matplotlib                   3.9.0\n",
      "mdurl                        0.1.2\n",
      "ml-dtypes                    0.3.2\n",
      "namex                        0.0.8\n",
      "numpy                        1.26.4\n",
      "opencv-python                4.10.0.82\n",
      "opt-einsum                   3.3.0\n",
      "optree                       0.11.0\n",
      "packaging                    24.0\n",
      "pillow                       10.3.0\n",
      "pip                          24.0\n",
      "protobuf                     4.25.3\n",
      "Pygments                     2.18.0\n",
      "pyparsing                    3.1.2\n",
      "python-dateutil              2.9.0.post0\n",
      "requests                     2.32.3\n",
      "rich                         13.7.1\n",
      "setuptools                   69.5.1\n",
      "six                          1.16.0\n",
      "tensorboard                  2.16.2\n",
      "tensorboard-data-server      0.7.2\n",
      "tensorflow                   2.16.1\n",
      "tensorflow-io-gcs-filesystem 0.37.0\n",
      "termcolor                    2.4.0\n",
      "typing_extensions            4.12.1\n",
      "urllib3                      2.2.1\n",
      "Werkzeug                     3.0.3\n",
      "wheel                        0.43.0\n",
      "wrapt                        1.16.0\n",
      "zipp                         3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fdda84-1910-4694-9bc3-d53ffb77fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f680a89-c95e-44a1-86f0-5eac7741281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/fg1mgg754tsb416pc5slmlt40000gn/T/ipykernel_84069/4232469594.py:2: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4082c586-db8e-4f7f-aae1-753800a32859",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fa6ecb-ec4f-4090-b8e1-209ccdf6d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "371a7b46-1117-4dc8-8157-4e9dd15d9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir): \n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try: \n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in image_exts: \n",
    "                print('Image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            # os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74158a72-75c6-4d7c-affa-7d8e9abd92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find . -name \"*.DS_Store\" -type f -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46e9a826-cf49-4f6b-974f-8ddb51e5444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d5f806a-26f7-4a0a-ad30-492223c8912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'data'\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/validation'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d100659-2ba1-4212-90c2-b0ac56b0e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough samples in class test to split. Need at least 3 samples.\n"
     ]
    },
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'data/train/happy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(test_class_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Copy files to their respective directories\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m copy_files(train, class_dir, train_class_dir)\n\u001b[1;32m     54\u001b[0m copy_files(val, class_dir, val_class_dir)\n\u001b[1;32m     55\u001b[0m copy_files(test, class_dir, test_class_dir)\n",
      "Cell \u001b[0;32mIn[57], line 30\u001b[0m, in \u001b[0;36mcopy_files\u001b[0;34m(file_list, source_dir, target_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m src \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir, file_name)\n\u001b[1;32m     29\u001b[0m dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(target_dir, file_name)\n\u001b[0;32m---> 30\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopy(src, dst)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/shutil.py:431\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    430\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 431\u001b[0m copyfile(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    432\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/shutil.py:256\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    259\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'data/train/happy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the paths\n",
    "dataset_dir = 'data'\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/validation'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "def split_data(class_dir, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    images = os.listdir(class_dir)\n",
    "    if len(images) < 3:\n",
    "        raise ValueError(f\"Not enough samples in class {os.path.basename(class_dir)} to split. Need at least 3 samples.\")\n",
    "    \n",
    "    train_and_val, test = train_test_split(images, test_size=test_size, random_state=42)\n",
    "    train, val = train_test_split(train_and_val, test_size=val_size/(train_size + val_size), random_state=42)\n",
    "    \n",
    "    return train, val, test\n",
    "\n",
    "def copy_files(file_list, source_dir, target_dir):\n",
    "    for file_name in file_list:\n",
    "        src = os.path.join(source_dir, file_name)\n",
    "        dst = os.path.join(target_dir, file_name)\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "# Iterate over each class in the dataset\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        train, val, test = split_data(class_dir)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # Create class directories in train, val, and test folders\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    val_class_dir = os.path.join(val_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(val_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy files to their respective directories\n",
    "    copy_files(train, class_dir, train_class_dir)\n",
    "    copy_files(val, class_dir, val_class_dir)\n",
    "    copy_files(test, class_dir, test_class_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1e851-8472-4ccc-99cb-2fafd36b2867",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d548e051-bbb1-4c2b-9fe5-0c7aec0d5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73d0c7ad-f656-4192-9c95-c7815ab70340",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9d504e4-e936-4052-bc8f-d251d4dc0831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 534 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data.flow_from_directory(\n",
    "        'data',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4f8831f-4c5b-4e64-bf6d-ab62b63128b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd9d236-d0c5-4f03-8dd5-3ce6c4453335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lable\n",
    "# 0 ind= angry\n",
    "# 1 ind= calm\n",
    "# 2 ind= happy\n",
    "# 3 ind= sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8404f4a-49e7-451c-afa2-136c3d99dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        'data',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d07aab1-4e92-40a9-b15b-bf02e0d271cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size + val_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6bedfa2-8f3e-43ec-ad5a-c0f9aaf8cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ebce6ff-2987-4f15-97db-3d45452a9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23c58bc1-947d-47e7-8c6f-e0dbd3d33c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iterator.next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ee0b59f-64e5-42c3-a8d4-5b62367be950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff409cbf-0ef5-4b17-92a1-657b5d4a964c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa4cf809-b574-4079-84b1-61d4addc115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d285e916-5b1b-4e7b-af5f-7f392d17a6b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d_3\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m16\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m3\u001b[39m)))\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D())\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ndim \u001b[38;5;241m<\u001b[39m spec\u001b[38;5;241m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected min_ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mmin_ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Check dtype.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv2d_3\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 4)"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc81b9da-2be7-493a-b104-b6c30b0f672d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate= 2e-5),\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.Accuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5dab2a09-d91c-40d3-ab6b-e13673a2cfc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14400)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               3686656   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3697396 (14.10 MB)\n",
      "Trainable params: 3697396 (14.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "234a618b-d7aa-4e5c-98b8-6cef4a33def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "502a93da-8c58-4f11-aa72-830352b5f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc7500e0-0bb8-4e70-a3a4-27e1ef8fc00d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/q_/fg1mgg754tsb416pc5slmlt40000gn/T/ipykernel_84069/2029832520.py\", line 1, in <module>\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1478]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mval, callbacks\u001b[38;5;241m=\u001b[39m[tensorboard_callback])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/var/folders/q_/fg1mgg754tsb416pc5slmlt40000gn/T/ipykernel_84069/2029832520.py\", line 1, in <module>\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/Users/saksham/anaconda3/lib/python3.11/site-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,4] and labels shape [128]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1478]"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38609fb7-86fb-4447-9a1f-f3f01b1f8267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotions",
   "language": "python",
   "name": "emotions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
